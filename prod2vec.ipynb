{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4918d0d-59fa-4fcb-8b98-b2c7557a46b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10fd67d9-1439-49f0-abac-76bcc897b932",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"renttherunway.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b25097e9-6d14-4410-b1b0-f478147c0ef2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit</th>\n",
       "      <th>user_id</th>\n",
       "      <th>bust size</th>\n",
       "      <th>item_id</th>\n",
       "      <th>weight</th>\n",
       "      <th>rating</th>\n",
       "      <th>rented for</th>\n",
       "      <th>review_text</th>\n",
       "      <th>body type</th>\n",
       "      <th>review_summary</th>\n",
       "      <th>category</th>\n",
       "      <th>height</th>\n",
       "      <th>size</th>\n",
       "      <th>age</th>\n",
       "      <th>review_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fit</td>\n",
       "      <td>420272</td>\n",
       "      <td>34d</td>\n",
       "      <td>2260466</td>\n",
       "      <td>137lbs</td>\n",
       "      <td>10.0</td>\n",
       "      <td>vacation</td>\n",
       "      <td>An adorable romper! Belt and zipper were a lit...</td>\n",
       "      <td>hourglass</td>\n",
       "      <td>So many compliments!</td>\n",
       "      <td>romper</td>\n",
       "      <td>5' 8\"</td>\n",
       "      <td>14</td>\n",
       "      <td>28.0</td>\n",
       "      <td>April 20, 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fit</td>\n",
       "      <td>273551</td>\n",
       "      <td>34b</td>\n",
       "      <td>153475</td>\n",
       "      <td>132lbs</td>\n",
       "      <td>10.0</td>\n",
       "      <td>other</td>\n",
       "      <td>I rented this dress for a photo shoot. The the...</td>\n",
       "      <td>straight &amp; narrow</td>\n",
       "      <td>I felt so glamourous!!!</td>\n",
       "      <td>gown</td>\n",
       "      <td>5' 6\"</td>\n",
       "      <td>12</td>\n",
       "      <td>36.0</td>\n",
       "      <td>June 18, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fit</td>\n",
       "      <td>360448</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1063761</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>party</td>\n",
       "      <td>This hugged in all the right places! It was a ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>It was a great time to celebrate the (almost) ...</td>\n",
       "      <td>sheath</td>\n",
       "      <td>5' 4\"</td>\n",
       "      <td>4</td>\n",
       "      <td>116.0</td>\n",
       "      <td>December 14, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fit</td>\n",
       "      <td>909926</td>\n",
       "      <td>34c</td>\n",
       "      <td>126335</td>\n",
       "      <td>135lbs</td>\n",
       "      <td>8.0</td>\n",
       "      <td>formal affair</td>\n",
       "      <td>I rented this for my company's black tie award...</td>\n",
       "      <td>pear</td>\n",
       "      <td>Dress arrived on time and in perfect condition.</td>\n",
       "      <td>dress</td>\n",
       "      <td>5' 5\"</td>\n",
       "      <td>8</td>\n",
       "      <td>34.0</td>\n",
       "      <td>February 12, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fit</td>\n",
       "      <td>151944</td>\n",
       "      <td>34b</td>\n",
       "      <td>616682</td>\n",
       "      <td>145lbs</td>\n",
       "      <td>10.0</td>\n",
       "      <td>wedding</td>\n",
       "      <td>I have always been petite in my upper body and...</td>\n",
       "      <td>athletic</td>\n",
       "      <td>Was in love with this dress !!!</td>\n",
       "      <td>gown</td>\n",
       "      <td>5' 9\"</td>\n",
       "      <td>12</td>\n",
       "      <td>27.0</td>\n",
       "      <td>September 26, 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192539</th>\n",
       "      <td>fit</td>\n",
       "      <td>66386</td>\n",
       "      <td>34dd</td>\n",
       "      <td>2252812</td>\n",
       "      <td>140lbs</td>\n",
       "      <td>10.0</td>\n",
       "      <td>work</td>\n",
       "      <td>Fit like a glove!</td>\n",
       "      <td>hourglass</td>\n",
       "      <td>LOVE IT!!! First Item Im thinking of buying!</td>\n",
       "      <td>jumpsuit</td>\n",
       "      <td>5' 9\"</td>\n",
       "      <td>8</td>\n",
       "      <td>42.0</td>\n",
       "      <td>May 18, 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192540</th>\n",
       "      <td>fit</td>\n",
       "      <td>118398</td>\n",
       "      <td>32c</td>\n",
       "      <td>682043</td>\n",
       "      <td>100lbs</td>\n",
       "      <td>10.0</td>\n",
       "      <td>work</td>\n",
       "      <td>The pattern contrast on this dress is really s...</td>\n",
       "      <td>petite</td>\n",
       "      <td>LOVE it!</td>\n",
       "      <td>dress</td>\n",
       "      <td>5' 1\"</td>\n",
       "      <td>4</td>\n",
       "      <td>29.0</td>\n",
       "      <td>September 30, 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192541</th>\n",
       "      <td>fit</td>\n",
       "      <td>47002</td>\n",
       "      <td>36a</td>\n",
       "      <td>683251</td>\n",
       "      <td>135lbs</td>\n",
       "      <td>6.0</td>\n",
       "      <td>everyday</td>\n",
       "      <td>Like the other DVF wraps, the fit on this is f...</td>\n",
       "      <td>straight &amp; narrow</td>\n",
       "      <td>Loud patterning, flattering fit</td>\n",
       "      <td>dress</td>\n",
       "      <td>5' 8\"</td>\n",
       "      <td>8</td>\n",
       "      <td>31.0</td>\n",
       "      <td>March 4, 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192542</th>\n",
       "      <td>fit</td>\n",
       "      <td>961120</td>\n",
       "      <td>36c</td>\n",
       "      <td>126335</td>\n",
       "      <td>165lbs</td>\n",
       "      <td>10.0</td>\n",
       "      <td>wedding</td>\n",
       "      <td>This dress was PERFECTION.  it looked incredib...</td>\n",
       "      <td>pear</td>\n",
       "      <td>loved this dress it was comfortable and photog...</td>\n",
       "      <td>dress</td>\n",
       "      <td>5' 6\"</td>\n",
       "      <td>16</td>\n",
       "      <td>31.0</td>\n",
       "      <td>November 25, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192543</th>\n",
       "      <td>fit</td>\n",
       "      <td>123612</td>\n",
       "      <td>36b</td>\n",
       "      <td>127865</td>\n",
       "      <td>155lbs</td>\n",
       "      <td>10.0</td>\n",
       "      <td>wedding</td>\n",
       "      <td>This dress was wonderful! I had originally pla...</td>\n",
       "      <td>athletic</td>\n",
       "      <td>I wore this to a beautiful black tie optional ...</td>\n",
       "      <td>gown</td>\n",
       "      <td>5' 6\"</td>\n",
       "      <td>16</td>\n",
       "      <td>30.0</td>\n",
       "      <td>August 29, 2017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>192544 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        fit  user_id bust size  item_id  weight  rating     rented for  \\\n",
       "0       fit   420272       34d  2260466  137lbs    10.0       vacation   \n",
       "1       fit   273551       34b   153475  132lbs    10.0          other   \n",
       "2       fit   360448       NaN  1063761     NaN    10.0          party   \n",
       "3       fit   909926       34c   126335  135lbs     8.0  formal affair   \n",
       "4       fit   151944       34b   616682  145lbs    10.0        wedding   \n",
       "...     ...      ...       ...      ...     ...     ...            ...   \n",
       "192539  fit    66386      34dd  2252812  140lbs    10.0           work   \n",
       "192540  fit   118398       32c   682043  100lbs    10.0           work   \n",
       "192541  fit    47002       36a   683251  135lbs     6.0       everyday   \n",
       "192542  fit   961120       36c   126335  165lbs    10.0        wedding   \n",
       "192543  fit   123612       36b   127865  155lbs    10.0        wedding   \n",
       "\n",
       "                                              review_text          body type  \\\n",
       "0       An adorable romper! Belt and zipper were a lit...          hourglass   \n",
       "1       I rented this dress for a photo shoot. The the...  straight & narrow   \n",
       "2       This hugged in all the right places! It was a ...                NaN   \n",
       "3       I rented this for my company's black tie award...               pear   \n",
       "4       I have always been petite in my upper body and...           athletic   \n",
       "...                                                   ...                ...   \n",
       "192539                                  Fit like a glove!          hourglass   \n",
       "192540  The pattern contrast on this dress is really s...             petite   \n",
       "192541  Like the other DVF wraps, the fit on this is f...  straight & narrow   \n",
       "192542  This dress was PERFECTION.  it looked incredib...               pear   \n",
       "192543  This dress was wonderful! I had originally pla...           athletic   \n",
       "\n",
       "                                           review_summary  category height  \\\n",
       "0                                    So many compliments!    romper  5' 8\"   \n",
       "1                                 I felt so glamourous!!!      gown  5' 6\"   \n",
       "2       It was a great time to celebrate the (almost) ...    sheath  5' 4\"   \n",
       "3        Dress arrived on time and in perfect condition.      dress  5' 5\"   \n",
       "4                         Was in love with this dress !!!      gown  5' 9\"   \n",
       "...                                                   ...       ...    ...   \n",
       "192539       LOVE IT!!! First Item Im thinking of buying!  jumpsuit  5' 9\"   \n",
       "192540                                           LOVE it!     dress  5' 1\"   \n",
       "192541                    Loud patterning, flattering fit     dress  5' 8\"   \n",
       "192542  loved this dress it was comfortable and photog...     dress  5' 6\"   \n",
       "192543  I wore this to a beautiful black tie optional ...      gown  5' 6\"   \n",
       "\n",
       "        size    age         review_date  \n",
       "0         14   28.0      April 20, 2016  \n",
       "1         12   36.0       June 18, 2013  \n",
       "2          4  116.0   December 14, 2015  \n",
       "3          8   34.0   February 12, 2014  \n",
       "4         12   27.0  September 26, 2016  \n",
       "...      ...    ...                 ...  \n",
       "192539     8   42.0        May 18, 2016  \n",
       "192540     4   29.0  September 30, 2016  \n",
       "192541     8   31.0       March 4, 2016  \n",
       "192542    16   31.0   November 25, 2015  \n",
       "192543    16   30.0     August 29, 2017  \n",
       "\n",
       "[192544 rows x 15 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af08619b-7d08-448e-a0ff-dfebd31f7de2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(192544, 15)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1310ec91-18b5-4d16-af85-b79f2f776117",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['fit', 'user_id', 'bust size', 'item_id', 'weight', 'rating',\n",
       "       'rented for', 'review_text', 'body type', 'review_summary',\n",
       "       'category', 'height', 'size', 'age', 'review_date'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a177228-6b2e-4ca1-b02e-db4820a5e4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0201c52b-44e6-4e65-84cf-046c8d529232",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c5440547-bcd2-486f-82eb-73f279f70aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "95f3eeb2-fa23-46df-a2de-930cc0371c66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/kolluri/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "420b4699-e07d-404d-8653-16550681e4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "72d4e288-73f1-423a-aa56-dbdbc8a725fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "print(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "22eac3f3-e9bf-4446-bcb2-2ba661622b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def review_to_words( raw_review ):\n",
    "    # Function to convert a raw review to a string of words\n",
    "    # The input is a single string (a raw movie review), and \n",
    "    # the output is a single string (a preprocessed movie review)\n",
    "    #\n",
    "    # 1. Remove HTML\n",
    "    review_text = BeautifulSoup(raw_review).get_text() \n",
    "    #\n",
    "    # 2. Remove non-letters        \n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", review_text) \n",
    "    #\n",
    "    # 3. Convert to lower case, split into individual words\n",
    "    words = letters_only.lower().split()                             \n",
    "    #\n",
    "    # 4. In Python, searching a set is much faster than searching\n",
    "    #   a list, so convert the stop words to a set\n",
    "    stops = set(stopwords.words(\"english\"))                  \n",
    "    # \n",
    "    # 5. Remove stop words\n",
    "    meaningful_words = [w for w in words if not w in stops]   \n",
    "    #\n",
    "    # 6. Join the words back into one string separated by space, \n",
    "    # and return the result.\n",
    "    return( \" \".join( meaningful_words )) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "efdbc44b-d703-4b3b-bb9e-bdec826e6070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adorable romper belt zipper little hard navigate full day wear bathroom use expected wish pockets absolutely perfect got million compliments\n"
     ]
    }
   ],
   "source": [
    "clean_review = review_to_words( train[\"review_text\"][0] )\n",
    "print(clean_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4e9bd4e9-05b2-408c-8bac-5f40678cbce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7c16fc7b-cd08-4bf5-9062-84a8402c786e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import various modules for string cleaning\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def review_to_wordlist( review, remove_stopwords=False ):\n",
    "    # Function to convert a document to a sequence of words,\n",
    "    # optionally removing stop words.  Returns a list of words.\n",
    "    #\n",
    "    # 1. Remove HTML\n",
    "    review_text = BeautifulSoup(review).get_text()\n",
    "    #  \n",
    "    # 2. Remove non-letters\n",
    "    review_text = re.sub(\"[^a-zA-Z]\",\" \", review_text)\n",
    "    #\n",
    "    # 3. Convert words to lower case and split them\n",
    "    words = review_text.lower().split()\n",
    "    #\n",
    "    # 4. Optionally remove stop words (false by default)\n",
    "    if remove_stopwords:\n",
    "        stops = set(stopwords.words(\"english\"))\n",
    "        words = [w for w in words if not w in stops]\n",
    "    #\n",
    "    # 5. Return a list of words\n",
    "    return(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b21abb1d-489a-4ce0-b90d-7cee82cb9f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "01be9663-54dd-4e97-852b-a002a8a62797",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/kolluri/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "50e5da25-928a-43c6-a05e-8bbc4ac72ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the punkt tokenizer\n",
    "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "33bad4fa-d690-4e79-9592-da30ad2000b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to split a review into parsed sentences\n",
    "def review_to_sentences( review, tokenizer, remove_stopwords=False ):\n",
    "    # Function to split a review into parsed sentences. Returns a \n",
    "    # list of sentences, where each sentence is a list of words\n",
    "    #\n",
    "    # 1. Use the NLTK tokenizer to split the paragraph into sentences\n",
    "    raw_sentences = tokenizer.tokenize(review.strip())\n",
    "    #\n",
    "    # 2. Loop over each sentence\n",
    "    sentences = []\n",
    "    for raw_sentence in raw_sentences:\n",
    "        # If a sentence is empty, skip it\n",
    "        if len(raw_sentence) > 0:\n",
    "            # Otherwise, call review_to_wordlist to get a list of words\n",
    "            sentences.append( review_to_wordlist( raw_sentence, \\\n",
    "              remove_stopwords ))\n",
    "    #\n",
    "    # Return the list of sentences (each sentence is a list of words,\n",
    "    # so this returns a list of lists\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ca0f48f1-5b97-4314-be44-c7d3f22f7dee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing sentences from training set\n"
     ]
    }
   ],
   "source": [
    "products = []  # Initialize an empty list of sentences\n",
    "\n",
    "print(\"Parsing sentences from training set\")\n",
    "for review in train[\"category\"]:\n",
    "    products += review_to_sentences(review, tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "bc00b590-2059-40a6-b20a-7c51bdaa00a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "192544\n"
     ]
    }
   ],
   "source": [
    "print(len(products))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ce49cf27-385e-466a-9f79-13159762ede9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['romper']\n"
     ]
    }
   ],
   "source": [
    "print(products[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c51e3ecd-fc95-4d31-a834-96f144522982",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gown']\n"
     ]
    }
   ],
   "source": [
    "print(products[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5023e1a6-f815-479f-931e-4e08126be142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sheath']\n"
     ]
    }
   ],
   "source": [
    "print(products[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "58fa35aa-3eed-494f-bc28-f9271bade595",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dress']\n"
     ]
    }
   ],
   "source": [
    "print(products[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1c1887de-76fe-466b-a45a-c181d788ac50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gown']\n"
     ]
    }
   ],
   "source": [
    "print(products[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b7d9749c-0234-4068-8de0-63b754bc838a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already up-to-date: gensim in /home/kolluri/.local/lib/python3.8/site-packages (4.1.2)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.17.0 in /apps/spack/brown/apps/anaconda/2020.11-py38-gcc-4.8.5-djkvkvk/lib/python3.8/site-packages (from gensim) (1.19.2)\n",
      "Requirement already satisfied, skipping upgrade: smart-open>=1.8.1 in /home/kolluri/.local/lib/python3.8/site-packages (from gensim) (5.2.1)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.18.1 in /apps/spack/brown/apps/anaconda/2020.11-py38-gcc-4.8.5-djkvkvk/lib/python3.8/site-packages (from gensim) (1.5.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d34f1f66-b7eb-4d1d-8bd5-ddafa1835914",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-13 21:23:33,660 : INFO : collecting all words and their counts\n",
      "2021-10-13 21:23:33,661 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2021-10-13 21:23:33,684 : INFO : PROGRESS: at sentence #10000, processed 131820 words, keeping 4614 word types\n",
      "2021-10-13 21:23:33,701 : INFO : collected 5828 word types from a corpus of 226711 raw words and 17150 sentences\n",
      "2021-10-13 21:23:33,703 : INFO : Creating a fresh vocabulary\n",
      "2021-10-13 21:23:33,735 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=40 retains 577 unique words (9.90048043925875%% of original 5828, drops 5251)', 'datetime': '2021-10-13T21:23:33.708239', 'gensim': '4.1.2', 'python': '3.8.5 (default, Sep  4 2020, 07:30:14) \\n[GCC 7.3.0]', 'platform': 'Linux-3.10.0-1062.9.1.el7.x86_64-x86_64-with-glibc2.10', 'event': 'prepare_vocab'}\n",
      "2021-10-13 21:23:33,736 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=40 leaves 201387 word corpus (88.8298318123073%% of original 226711, drops 25324)', 'datetime': '2021-10-13T21:23:33.736818', 'gensim': '4.1.2', 'python': '3.8.5 (default, Sep  4 2020, 07:30:14) \\n[GCC 7.3.0]', 'platform': 'Linux-3.10.0-1062.9.1.el7.x86_64-x86_64-with-glibc2.10', 'event': 'prepare_vocab'}\n",
      "2021-10-13 21:23:33,741 : INFO : deleting the raw counts dictionary of 5828 items\n",
      "2021-10-13 21:23:33,743 : INFO : sample=0.001 downsamples 66 most-common words\n",
      "2021-10-13 21:23:33,744 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 119530.03665280867 word corpus (59.4%% of prior 201387)', 'datetime': '2021-10-13T21:23:33.744925', 'gensim': '4.1.2', 'python': '3.8.5 (default, Sep  4 2020, 07:30:14) \\n[GCC 7.3.0]', 'platform': 'Linux-3.10.0-1062.9.1.el7.x86_64-x86_64-with-glibc2.10', 'event': 'prepare_vocab'}\n",
      "2021-10-13 21:23:33,751 : INFO : estimated required memory for 577 words and 100 dimensions: 750100 bytes\n",
      "2021-10-13 21:23:33,753 : INFO : resetting layer weights\n",
      "2021-10-13 21:23:33,755 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2021-10-13T21:23:33.755523', 'gensim': '4.1.2', 'python': '3.8.5 (default, Sep  4 2020, 07:30:14) \\n[GCC 7.3.0]', 'platform': 'Linux-3.10.0-1062.9.1.el7.x86_64-x86_64-with-glibc2.10', 'event': 'build_vocab'}\n",
      "2021-10-13 21:23:33,757 : INFO : Word2Vec lifecycle event {'msg': 'training model with 4 workers on 577 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2021-10-13T21:23:33.757263', 'gensim': '4.1.2', 'python': '3.8.5 (default, Sep  4 2020, 07:30:14) \\n[GCC 7.3.0]', 'platform': 'Linux-3.10.0-1062.9.1.el7.x86_64-x86_64-with-glibc2.10', 'event': 'train'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-13 21:23:33,922 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-10-13 21:23:33,929 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-10-13 21:23:33,941 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-10-13 21:23:33,945 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-10-13 21:23:33,945 : INFO : EPOCH - 1 : training on 226711 raw words (119302 effective words) took 0.2s, 656623 effective words/s\n",
      "2021-10-13 21:23:34,105 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-10-13 21:23:34,112 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-10-13 21:23:34,119 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-10-13 21:23:34,128 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-10-13 21:23:34,129 : INFO : EPOCH - 2 : training on 226711 raw words (119532 effective words) took 0.2s, 675930 effective words/s\n",
      "2021-10-13 21:23:34,291 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-10-13 21:23:34,298 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-10-13 21:23:34,307 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-10-13 21:23:34,309 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-10-13 21:23:34,309 : INFO : EPOCH - 3 : training on 226711 raw words (119231 effective words) took 0.2s, 686469 effective words/s\n",
      "2021-10-13 21:23:34,466 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-10-13 21:23:34,473 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-10-13 21:23:34,482 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-10-13 21:23:34,488 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-10-13 21:23:34,489 : INFO : EPOCH - 4 : training on 226711 raw words (119447 effective words) took 0.2s, 691850 effective words/s\n",
      "2021-10-13 21:23:34,645 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-10-13 21:23:34,652 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-10-13 21:23:34,661 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-10-13 21:23:34,668 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-10-13 21:23:34,668 : INFO : EPOCH - 5 : training on 226711 raw words (119317 effective words) took 0.2s, 692620 effective words/s\n",
      "2021-10-13 21:23:34,669 : INFO : Word2Vec lifecycle event {'msg': 'training on 1133555 raw words (596829 effective words) took 0.9s, 655838 effective words/s', 'datetime': '2021-10-13T21:23:34.668995', 'gensim': '4.1.2', 'python': '3.8.5 (default, Sep  4 2020, 07:30:14) \\n[GCC 7.3.0]', 'platform': 'Linux-3.10.0-1062.9.1.el7.x86_64-x86_64-with-glibc2.10', 'event': 'train'}\n",
      "2021-10-13 21:23:34,669 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=577, vector_size=100, alpha=0.025)', 'datetime': '2021-10-13T21:23:34.669436', 'gensim': '4.1.2', 'python': '3.8.5 (default, Sep  4 2020, 07:30:14) \\n[GCC 7.3.0]', 'platform': 'Linux-3.10.0-1062.9.1.el7.x86_64-x86_64-with-glibc2.10', 'event': 'created'}\n",
      "<ipython-input-44-14306d2a08b7>:21: DeprecationWarning: Call to deprecated `init_sims` (Gensim 4.0.0 implemented internal optimizations that make calls to init_sims() unnecessary. init_sims() is now obsoleted and will be completely removed in future versions. See https://github.com/RaRe-Technologies/gensim/wiki/Migrating-from-Gensim-3.x-to-4).\n",
      "  model.init_sims(replace=True)\n",
      "2021-10-13 21:23:34,670 : WARNING : destructive init_sims(replace=True) deprecated & no longer required for space-efficiency\n",
      "2021-10-13 21:23:34,670 : INFO : Word2Vec lifecycle event {'fname_or_handle': '300features_40minwords_10context', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2021-10-13T21:23:34.670740', 'gensim': '4.1.2', 'python': '3.8.5 (default, Sep  4 2020, 07:30:14) \\n[GCC 7.3.0]', 'platform': 'Linux-3.10.0-1062.9.1.el7.x86_64-x86_64-with-glibc2.10', 'event': 'saving'}\n",
      "2021-10-13 21:23:34,671 : INFO : not storing attribute cum_table\n",
      "2021-10-13 21:23:34,687 : INFO : saved 300features_40minwords_10context\n"
     ]
    }
   ],
   "source": [
    "# Import the built-in logging module and configure it so that Word2Vec \n",
    "# creates nice output messages\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s',\\\n",
    "    level=logging.INFO)\n",
    "\n",
    "# Set values for various parameters\n",
    "num_features = 300    # Word vector dimensionality                      \n",
    "min_word_count = 40   # Minimum word count                        \n",
    "num_workers = 4       # Number of threads to run in parallel\n",
    "context = 10          # Context window size                                                                                    \n",
    "downsampling = 1e-3   # Downsample setting for frequent words\n",
    "\n",
    "# Initialize and train the model (this will take some time)\n",
    "from gensim.models import word2vec\n",
    "print(\"Training model...\")\n",
    "model = word2vec.Word2Vec(sentences, workers=num_workers, min_count = min_word_count, window = context, sample = downsampling)\n",
    "\n",
    "# If you don't plan to train the model any further, calling \n",
    "# init_sims will make the model much more memory-efficient.\n",
    "model.init_sims(replace=True)\n",
    "\n",
    "# It can be helpful to create a meaningful model name and \n",
    "# save the model for later use. You can load it later using Word2Vec.load()\n",
    "model_name = \"300features_40minwords_10context\"\n",
    "model.save(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d0488ca1-cfe3-4077-aaf8-75cf71f7ff3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('appropriate', 0.8480944633483887),\n",
       " ('great', 0.7676073908805847),\n",
       " ('winter', 0.7248153686523438),\n",
       " ('summer', 0.7167755961418152),\n",
       " ('fall', 0.7130144834518433),\n",
       " ('holiday', 0.6903368830680847),\n",
       " ('casual', 0.6832987666130066),\n",
       " ('tie', 0.6819866895675659),\n",
       " ('gala', 0.6744628548622131),\n",
       " ('bachelorette', 0.6718504428863525)]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('perfect') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f13bfe8e-deaa-4638-b24a-53a95b1f3946",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('jumpsuit', 0.9770253300666809),\n",
       " ('wonderful', 0.96225506067276),\n",
       " ('shirt', 0.9560211896896362),\n",
       " ('gown', 0.9536227583885193),\n",
       " ('classic', 0.9518102407455444),\n",
       " ('outfit', 0.951670229434967),\n",
       " ('fabulous', 0.9375145435333252),\n",
       " ('every', 0.9339058995246887),\n",
       " ('piece', 0.927277147769928),\n",
       " ('customer', 0.9220750331878662)]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(products[0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a9c343a3-88f5-4154-a341-21dd724100ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('jumpsuit', 0.9766460657119751),\n",
       " ('outfit', 0.9560984969139099),\n",
       " ('romper', 0.9536227583885193),\n",
       " ('new', 0.9330899119377136),\n",
       " ('weather', 0.9306640625),\n",
       " ('she', 0.9248742461204529),\n",
       " ('statement', 0.9239307045936584),\n",
       " ('jacket', 0.9210926294326782),\n",
       " ('classic', 0.9194459319114685),\n",
       " ('shirt', 0.917213499546051)]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(products[1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e18c2696-b2b5-4d5f-8bb9-e06c088fa727",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Key 'sheath' not present\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-68-bf135c0d1c14>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproducts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mmost_similar\u001b[0;34m(self, positive, negative, topn, clip_start, clip_end, restrict_vocab, indexer)\u001b[0m\n\u001b[1;32m    771\u001b[0m                 \u001b[0mmean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    772\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 773\u001b[0;31m                 \u001b[0mmean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    774\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_index_for\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    775\u001b[0m                     \u001b[0mall_keys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mget_vector\u001b[0;34m(self, key, norm)\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \"\"\"\n\u001b[0;32m--> 438\u001b[0;31m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    439\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill_norms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mget_index\u001b[0;34m(self, key, default)\u001b[0m\n\u001b[1;32m    410\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 412\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Key '{key}' not present\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    413\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"Key 'sheath' not present\""
     ]
    }
   ],
   "source": [
    "model.wv.most_similar(products[2]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4217c704-8cdc-409f-bc4e-2924f7f1a38b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('absolutely', 0.652269184589386),\n",
       " ('style', 0.6444486975669861),\n",
       " ('jumpsuit', 0.6417688131332397),\n",
       " ('gown', 0.6075455546379089),\n",
       " ('outfit', 0.6073992252349854),\n",
       " ('romper', 0.6004043817520142),\n",
       " ('rental', 0.5960897207260132),\n",
       " ('overall', 0.5881788730621338),\n",
       " ('color', 0.5807492733001709),\n",
       " ('shirt', 0.578428328037262)]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(products[3]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "591e9913-4586-4c57-ac14-097433cc8284",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dress']\n"
     ]
    }
   ],
   "source": [
    "print(products[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "969b4e16-7f41-49b7-a603-ef316cde0814",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('jumpsuit', 0.9766460657119751),\n",
       " ('outfit', 0.9560984969139099),\n",
       " ('romper', 0.9536227583885193),\n",
       " ('new', 0.9330899119377136),\n",
       " ('weather', 0.9306640625),\n",
       " ('she', 0.9248742461204529),\n",
       " ('statement', 0.9239307045936584),\n",
       " ('jacket', 0.9210926294326782),\n",
       " ('classic', 0.9194459319114685),\n",
       " ('shirt', 0.917213499546051)]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(products[4]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "42c5e726-5d1b-4a8b-955d-b9abb0883c46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('large', 0.9734272956848145),\n",
       " ('run', 0.9290880560874939),\n",
       " ('runs', 0.9252339601516724),\n",
       " ('larger', 0.9229534864425659),\n",
       " ('ran', 0.9167706966400146),\n",
       " ('medium', 0.9083396792411804),\n",
       " ('smaller', 0.9061229228973389),\n",
       " ('bust', 0.9050785303115845),\n",
       " ('chest', 0.8974775671958923),\n",
       " ('big', 0.8869579434394836)]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('small') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "fd78794e-c7d7-45a9-9fdc-9d2376591ab4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('nothing', 0.9441495537757874),\n",
       " ('flat', 0.9440214037895203),\n",
       " ('huge', 0.929150402545929),\n",
       " ('things', 0.9238819479942322),\n",
       " ('stars', 0.9210492968559265),\n",
       " ('myself', 0.9152724146842957),\n",
       " ('cleavage', 0.9144264459609985),\n",
       " ('issues', 0.9120636582374573),\n",
       " ('others', 0.9107150435447693),\n",
       " ('reason', 0.9050848484039307)]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('bad') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0b038aca-2c64-468a-acb9-7dec5e3128ba",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Key 'sheath' not present\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-74-9e8ed68ce273>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproducts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mmost_similar\u001b[0;34m(self, positive, negative, topn, clip_start, clip_end, restrict_vocab, indexer)\u001b[0m\n\u001b[1;32m    771\u001b[0m                 \u001b[0mmean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    772\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 773\u001b[0;31m                 \u001b[0mmean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    774\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_index_for\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    775\u001b[0m                     \u001b[0mall_keys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mget_vector\u001b[0;34m(self, key, norm)\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \"\"\"\n\u001b[0;32m--> 438\u001b[0;31m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    439\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill_norms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mget_index\u001b[0;34m(self, key, default)\u001b[0m\n\u001b[1;32m    410\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 412\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Key '{key}' not present\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    413\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"Key 'sheath' not present\""
     ]
    }
   ],
   "source": [
    "for i in range(len(sentences)):\n",
    "    model.wv.most_similar(products[i][0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc44b9e-2caa-4a11-be61-178530a72325",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 (Anaconda 2020.11)",
   "language": "python",
   "name": "anaconda-2020.11-py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
